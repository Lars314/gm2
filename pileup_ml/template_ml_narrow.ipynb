{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.18/04\n"
     ]
    }
   ],
   "source": [
    "import ROOT as r\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "import pickle\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './template_data/set_4/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "The purpose of this notebook is to train and test a machine learning algorithm to determine the number of pulses in an island. It should be able to look at an island and tells us with x% confidence that it is a single, double, triple, or quadruple pile up event\n",
    "\n",
    "This notebook looks closely at just three algorithms, but for different artificial pulse time offsets and training dataset sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(name, size=0.2):\n",
    "    with open(directory + 'data/x_'+name+'.data', 'rb') as xFile:\n",
    "        biggestX = pickle.load(xFile)\n",
    "        bigX = []\n",
    "        for x in biggestX:\n",
    "            bigX.append(x[1])\n",
    "        xFile.close()\n",
    "\n",
    "    with open(directory + 'data/y_'+name+'.data', 'rb') as yFile:\n",
    "        bigY = pickle.load(yFile)\n",
    "        yFile.close()\n",
    "        \n",
    "    return train_test_split(bigX, bigY, test_size=size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vary minTimeOffset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ starting minTime 0.0 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 0.5 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 1.0 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 1.5 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 2.0 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 2.5 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 3.0 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 3.5 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 4.0 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 4.5 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n"
     ]
    }
   ],
   "source": [
    "for minTime in np.linspace(0.0, 4.5, num=10):\n",
    "    print('------ starting minTime {0} ------'.format(minTime))\n",
    "\n",
    "    if(minTime < 1):\n",
    "        name = '0' + str(int(minTime*10))\n",
    "    else:\n",
    "        name = str(int(minTime*10))\n",
    "\n",
    "    print('generating train/test sets ...')    \n",
    "    x_train, x_test, y_train, y_test = getData(name)\n",
    "\n",
    "    print('training model ...')\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn_model.fit(x_train, y_train)\n",
    "\n",
    "    print('generating confusion matrix ...')\n",
    "    matrix = confusion_matrix(y_true=y_test,\n",
    "                              y_pred=knn_model.predict(x_test[:20001]),\n",
    "                              normalize='true')\n",
    "\n",
    "    confusionDf = pd.DataFrame(data=matrix,\n",
    "                               index=['0', '1', '2', '3', '4'],\n",
    "                               columns=['0', '1', '2', '3', '4'])\n",
    "\n",
    "    confusionDf.to_csv(directory + 'metrics/confusion_knn_' + name + '.csv')\n",
    "\n",
    "    dump(knn_model, directory + 'models/knn_' + name + '.joblib');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ starting minTime 0.0 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 0.5 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 1.0 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 1.5 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 2.0 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 2.5 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 3.0 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 3.5 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 4.0 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 4.5 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n"
     ]
    }
   ],
   "source": [
    "for minTime in np.linspace(0.0, 4.5, num=10):\n",
    "    print('------ starting minTime {0} ------'.format(minTime))\n",
    "\n",
    "    if(minTime < 1):\n",
    "        name = '0' + str(int(minTime*10))\n",
    "    else:\n",
    "        name = str(int(minTime*10))\n",
    "\n",
    "    print('generating train/test sets ...')    \n",
    "    x_train, x_test, y_train, y_test = getData(name)\n",
    "\n",
    "    print('training model ...')\n",
    "    rfc_model = RandomForestClassifier()\n",
    "    rfc_model.fit(x_train, y_train)\n",
    "\n",
    "    print('generating confusion matrix ...')\n",
    "    matrix = confusion_matrix(y_true=y_test,\n",
    "                              y_pred=rfc_model.predict(x_test[:20001]),\n",
    "                              normalize='true')\n",
    "\n",
    "    confusionDf = pd.DataFrame(data=matrix,\n",
    "                               index=['0', '1', '2', '3', '4'],\n",
    "                               columns=['0', '1', '2', '3', '4'])\n",
    "\n",
    "    confusionDf.to_csv(directory + 'metrics/confusion_rfc_' + name + '.csv')\n",
    "\n",
    "    dump(rfc_model, directory + 'models/rfc_' + name + '.joblib');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ starting minTime 0.0 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lars/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating confusion matrix ...\n",
      "------ starting minTime 0.5 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lars/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating confusion matrix ...\n",
      "------ starting minTime 1.0 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lars/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating confusion matrix ...\n",
      "------ starting minTime 1.5 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lars/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating confusion matrix ...\n",
      "------ starting minTime 2.0 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lars/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating confusion matrix ...\n",
      "------ starting minTime 2.5 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lars/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating confusion matrix ...\n",
      "------ starting minTime 3.0 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lars/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating confusion matrix ...\n",
      "------ starting minTime 3.5 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lars/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating confusion matrix ...\n",
      "------ starting minTime 4.0 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lars/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating confusion matrix ...\n",
      "------ starting minTime 4.5 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lars/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating confusion matrix ...\n"
     ]
    }
   ],
   "source": [
    "for minTime in np.linspace(0.0, 4.5, num=10):\n",
    "    print('------ starting minTime {0} ------'.format(minTime))\n",
    "\n",
    "    if(minTime < 1):\n",
    "        name = '0' + str(int(minTime*10))\n",
    "    else:\n",
    "        name = str(int(minTime*10))\n",
    "\n",
    "    print('generating train/test sets ...')    \n",
    "    x_train, x_test, y_train, y_test = getData(name)\n",
    "\n",
    "    print('training model ...')\n",
    "    mlp_model = MLPClassifier()\n",
    "    mlp_model.fit(x_train, y_train)\n",
    "\n",
    "    print('generating confusion matrix ...')\n",
    "    matrix = confusion_matrix(y_true=y_test,\n",
    "                              y_pred=mlp_model.predict(x_test[:20001]),\n",
    "                              normalize='true')\n",
    "\n",
    "    confusionDf = pd.DataFrame(data=matrix,\n",
    "                               index=['0', '1', '2', '3', '4'],\n",
    "                               columns=['0', '1', '2', '3', '4'])\n",
    "\n",
    "    confusionDf.to_csv(directory + 'metrics/confusion_mlp_' + name + '.csv')\n",
    "\n",
    "    dump(mlp_model, directory + 'models/mlp_' + name + '.joblib');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vary minTimeOffset, but only use the model trained on 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ starting minTime 0.0 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 0.5 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 1.0 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 1.5 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 2.0 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 2.5 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 3.0 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 3.5 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 4.0 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 4.5 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n"
     ]
    }
   ],
   "source": [
    "knn_model = load(directory + 'models/knn_00.joblib')\n",
    "\n",
    "for minTime in np.linspace(0.0, 4.5, num=10):\n",
    "    print('------ starting minTime {0} ------'.format(minTime))\n",
    "\n",
    "    if(minTime < 1):\n",
    "        name = '0' + str(int(minTime*10))\n",
    "    else:\n",
    "        name = str(int(minTime*10))\n",
    "\n",
    "    print('generating train/test sets ...')    \n",
    "    x_train, x_test, y_train, y_test = getData(name)\n",
    "\n",
    "    print('generating confusion matrix ...')\n",
    "    matrix = confusion_matrix(y_true=y_test,\n",
    "                              y_pred=knn_model.predict(x_test[:20001]),\n",
    "                              normalize='true')\n",
    "\n",
    "    confusionDf = pd.DataFrame(data=matrix,\n",
    "                               index=['0', '1', '2', '3', '4'],\n",
    "                               columns=['0', '1', '2', '3', '4'])\n",
    "\n",
    "    confusionDf.to_csv(directory + 'metrics_00/confusion_knn_' + name + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ starting minTime 0.0 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 0.5 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 1.0 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 1.5 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 2.0 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 2.5 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 3.0 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 3.5 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 4.0 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 4.5 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n"
     ]
    }
   ],
   "source": [
    "rfc_model = load(directory + 'models/rfc_00.joblib')\n",
    "\n",
    "for minTime in np.linspace(0.0, 4.5, num=10):\n",
    "    print('------ starting minTime {0} ------'.format(minTime))\n",
    "\n",
    "    if(minTime < 1):\n",
    "        name = '0' + str(int(minTime*10))\n",
    "    else:\n",
    "        name = str(int(minTime*10))\n",
    "\n",
    "    print('generating train/test sets ...')    \n",
    "    x_train, x_test, y_train, y_test = getData(name)\n",
    "\n",
    "    print('generating confusion matrix ...')\n",
    "    matrix = confusion_matrix(y_true=y_test,\n",
    "                              y_pred=rfc_model.predict(x_test[:20001]),\n",
    "                              normalize='true')\n",
    "\n",
    "    confusionDf = pd.DataFrame(data=matrix,\n",
    "                               index=['0', '1', '2', '3', '4'],\n",
    "                               columns=['0', '1', '2', '3', '4'])\n",
    "\n",
    "    confusionDf.to_csv(directory + 'metrics_00/confusion_rfc_' + name + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ starting minTime 0.0 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 0.5 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 1.0 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 1.5 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 2.0 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 2.5 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 3.0 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 3.5 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 4.0 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n",
      "------ starting minTime 4.5 ------\n",
      "generating train/test sets ...\n",
      "generating confusion matrix ...\n"
     ]
    }
   ],
   "source": [
    "mlp_model = load(directory + 'models/mlp_00.joblib')\n",
    "\n",
    "for minTime in np.linspace(0.0, 4.5, num=10):\n",
    "    print('------ starting minTime {0} ------'.format(minTime))\n",
    "\n",
    "    if(minTime < 1):\n",
    "        name = '0' + str(int(minTime*10))\n",
    "    else:\n",
    "        name = str(int(minTime*10))\n",
    "\n",
    "    print('generating train/test sets ...')    \n",
    "    x_train, x_test, y_train, y_test = getData(name)\n",
    "\n",
    "    print('generating confusion matrix ...')\n",
    "    matrix = confusion_matrix(y_true=y_test,\n",
    "                              y_pred=mlp_model.predict(x_test[:20001]),\n",
    "                              normalize='true')\n",
    "\n",
    "    confusionDf = pd.DataFrame(data=matrix,\n",
    "                               index=['0', '1', '2', '3', '4'],\n",
    "                               columns=['0', '1', '2', '3', '4'])\n",
    "\n",
    "    confusionDf.to_csv(directory + 'metrics_00/confusion_mlp_' + name + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vary training size\n",
    "\n",
    "use training sizes 10-80 thousand\n",
    "\n",
    "minPulseOffset=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ starting train size 1000 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting train size 2000 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting train size 3000 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting train size 4000 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting train size 5000 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting train size 6000 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting train size 7000 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting train size 8000 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n"
     ]
    }
   ],
   "source": [
    "for size in range(1000, 8001, 1000):\n",
    "    print('------ starting train size {0} ------'.format(size))\n",
    "    name = str(size)\n",
    "    \n",
    "    print('generating train/test sets ...')    \n",
    "    X_train, x_test, Y_train, y_test = getData('00')\n",
    "    \n",
    "    x_train = X_train[:size+1]\n",
    "    y_train = Y_train[:size+1]\n",
    "\n",
    "    print('training model ...')\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn_model.fit(x_train, y_train)\n",
    "\n",
    "    print('generating confusion matrix ...')\n",
    "    matrix = confusion_matrix(y_true=y_test,\n",
    "                              y_pred=knn_model.predict(x_test[:20001]),\n",
    "                              normalize='true')\n",
    "\n",
    "    confusionDf = pd.DataFrame(data=matrix,\n",
    "                               index=['0', '1', '2', '3', '4'],\n",
    "                               columns=['0', '1', '2', '3', '4'])\n",
    "\n",
    "    confusionDf.to_csv(directory + 'metrics_train_size/confusion_knn_' + name + '.csv')\n",
    "\n",
    "    dump(knn_model, directory + 'models_train_size/knn_' + name + '.joblib');\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ starting train size 1000 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting train size 2000 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting train size 3000 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting train size 4000 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting train size 5000 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting train size 6000 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting train size 7000 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n",
      "------ starting train size 8000 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n"
     ]
    }
   ],
   "source": [
    "X_train, x_test, Y_train, y_test = getData('00')\n",
    "\n",
    "for size in range(1000, 8001, 1000):\n",
    "    print('------ starting train size {0} ------'.format(size))\n",
    "    name = str(size)\n",
    "    \n",
    "    print('generating train/test sets ...')    \n",
    "    \n",
    "    x_train = X_train[:size+1]\n",
    "    y_train = Y_train[:size+1]\n",
    "\n",
    "    print('training model ...')\n",
    "    rfc_model = RandomForestClassifier()\n",
    "    rfc_model.fit(x_train, y_train)\n",
    "\n",
    "    print('generating confusion matrix ...')\n",
    "    matrix = confusion_matrix(y_true=y_test,\n",
    "                              y_pred=rfc_model.predict(x_test[:20001]),\n",
    "                              normalize='true')\n",
    "\n",
    "    confusionDf = pd.DataFrame(data=matrix,\n",
    "                               index=['0', '1', '2', '3', '4'],\n",
    "                               columns=['0', '1', '2', '3', '4'])\n",
    "\n",
    "    confusionDf.to_csv(directory + 'metrics_train_size/confusion_rfc_' + name + '.csv')\n",
    "\n",
    "    dump(rfc_model, directory + 'models_train_size/rfc_' + name + '.joblib');\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ starting train size 1000 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lars/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating confusion matrix ...\n",
      "------ starting train size 2000 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lars/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating confusion matrix ...\n",
      "------ starting train size 3000 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lars/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating confusion matrix ...\n",
      "------ starting train size 4000 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lars/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating confusion matrix ...\n",
      "------ starting train size 5000 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lars/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating confusion matrix ...\n",
      "------ starting train size 6000 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lars/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating confusion matrix ...\n",
      "------ starting train size 7000 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lars/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating confusion matrix ...\n",
      "------ starting train size 8000 ------\n",
      "generating train/test sets ...\n",
      "training model ...\n",
      "generating confusion matrix ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lars/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, x_test, Y_train, y_test = getData('00')\n",
    "\n",
    "for size in range(1000, 8001, 1000):\n",
    "    print('------ starting train size {0} ------'.format(size))\n",
    "    name = str(size)\n",
    "    \n",
    "    print('generating train/test sets ...')    \n",
    "        \n",
    "    x_train = X_train[:size+1]\n",
    "    y_train = Y_train[:size+1]\n",
    "\n",
    "    print('training model ...')\n",
    "    mlp_model = MLPClassifier()\n",
    "    mlp_model.fit(x_train, y_train)\n",
    "\n",
    "    print('generating confusion matrix ...')\n",
    "    matrix = confusion_matrix(y_true=y_test,\n",
    "                              y_pred=mlp_model.predict(x_test[:20001]),\n",
    "                              normalize='true')\n",
    "\n",
    "    confusionDf = pd.DataFrame(data=matrix,\n",
    "                               index=['0', '1', '2', '3', '4'],\n",
    "                               columns=['0', '1', '2', '3', '4'])\n",
    "\n",
    "    confusionDf.to_csv(directory + 'metrics_train_size/confusion_mlp_' + name + '.csv')\n",
    "\n",
    "    dump(mlp_model, directory + 'models_train_size/mlp_' + name + '.joblib');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
